{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7rWA2+CdkofyVuTbbKD88",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ellerywuyn/LEAR-lab/blob/1-compare-existing-profanity-models/profanity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil"
      ],
      "metadata": {
        "id": "L_gxS6ESq7-C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('cardiffnlp', ignore_errors=True)"
      ],
      "metadata": {
        "id": "tWMYm0I2q9DY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vNlesuGf9N9",
        "outputId": "65f02b71-38fa-442f-ba36-7b51295520fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-roberta-base-offensive\")\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-roberta-base-offensive\")"
      ],
      "metadata": {
        "id": "9sX6dzPprSfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "duCyYoU1mEKw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "import csv\n",
        "import urllib.request\n",
        "\n",
        "# Preprocess text (username and link placeholders)\n",
        "def preprocess(text):\n",
        "    new_text = []\n",
        "    for t in text.split(\" \"):\n",
        "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
        "        t = 'http' if t.startswith('http') else t\n",
        "        new_text.append(t)\n",
        "    return \" \".join(new_text)\n",
        "\n",
        "# Tasks:\n",
        "# emoji, emotion, hate, irony, offensive, sentiment\n",
        "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
        "task='offensive'\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "\n",
        "# PT\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "model.save_pretrained(MODEL)\n",
        "tokenizer.save_pretrained(MODEL)\n",
        "\n",
        "# download label mapping\n",
        "labels=[]\n",
        "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
        "with urllib.request.urlopen(mapping_link) as f:\n",
        "    html = f.read().decode('utf-8').split(\"\\n\")\n",
        "    csvreader = csv.reader(html, delimiter='\\t')\n",
        "labels = [row[1] for row in csvreader if len(row) > 1]\n",
        "\n",
        "# # TF\n",
        "# model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
        "# model.save_pretrained(MODEL)\n",
        "\n",
        "# text = \"Good night ðŸ˜Š\"\n",
        "# encoded_input = tokenizer(text, return_tensors='tf')\n",
        "# output = model(encoded_input)\n",
        "# scores = output[0][0].numpy()\n",
        "# scores = softmax(scores)\n"
      ],
      "metadata": {
        "id": "maeHkS5Ogb8t"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Good night ðŸ˜Š\"\n",
        "text = preprocess(text)\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "output = model(**encoded_input)\n",
        "scores = output[0][0].detach().numpy()\n",
        "scores = softmax(scores)\n",
        "\n",
        "ranking = np.argsort(scores)\n",
        "ranking = ranking[::-1]\n",
        "for i in range(scores.shape[0]):\n",
        "    l = labels[ranking[i]]\n",
        "    s = scores[ranking[i]]\n",
        "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX9ixLtsg8qO",
        "outputId": "3155fbd5-36fa-4e5d-b8fe-05512698294a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1) not-offensive 0.9073\n",
            "2) offensive 0.0927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 235 words\n",
        "text = \"Economists see the real world as one in which peopleâ€™s desires exceed what is possible â€“ in other words, in terms of scarcity. \\\n",
        "Economic behavior involves tradeoffs in which individuals, firms, and society must forgo something that they desire to obtain things that they desire more.\\\n",
        "Individuals face the tradeoff of what quantities of goods and services to consume.\\\n",
        "The budget constraint, which is the frontier of the opportunity set, illustrates the range of available choices. The relative price of the choices determines the slope of the budget constraint. Choices beyond the budget constraint are not affordable.\\\n",
        "Opportunity cost measures cost by what we forgo in exchange for the goods and services we consume. Sometimes we can measure opportunity cost in money, but it is often useful to consider time as well, or to measure it in terms of the actual resources that we must forfeit.\\\n",
        "Most economic decisions and tradeoffs are not all-or-nothing. Instead, they involve marginal analysis, which means they are about decisions on the margin, involving a little more or a little less.\\\n",
        "The law of diminishing marginal utility points out that as a person receives more of somethingâ€”whether it is a specific good or another resourceâ€”the additional marginal gains tend to become smaller.\\\n",
        "Because sunk costs occurred in the past and cannot be recovered, they should be disregarded in making current decisions.\"\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "text = preprocess(text)\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "output = model(**encoded_input)\n",
        "scores = output[0][0].detach().numpy()\n",
        "scores = softmax(scores)\n",
        "\n",
        "ranking = np.argsort(scores)\n",
        "ranking = ranking[::-1]\n",
        "for i in range(scores.shape[0]):\n",
        "    l = labels[ranking[i]]\n",
        "    s = scores[ranking[i]]\n",
        "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "print(\"total time:\", total_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWCtpGMmjWqW",
        "outputId": "8f827ee4-74b7-4ce2-fdc2-e0ed12c46e32"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1) not-offensive 0.8946\n",
            "2) offensive 0.1054\n",
            "total time: 0.7390432357788086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"You suck\"\n",
        "text = preprocess(text)\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "output = model(**encoded_input)\n",
        "scores = output[0][0].detach().numpy()\n",
        "scores = softmax(scores)\n",
        "\n",
        "ranking = np.argsort(scores)\n",
        "ranking = ranking[::-1]\n",
        "for i in range(scores.shape[0]):\n",
        "    l = labels[ranking[i]]\n",
        "    s = scores[ranking[i]]\n",
        "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
      ],
      "metadata": {
        "id": "AWNelu6RlWVg",
        "outputId": "f1d6accd-74f1-4581-ae47-a11070091db4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1) offensive 0.8645\n",
            "2) not-offensive 0.1355\n"
          ]
        }
      ]
    }
  ]
}